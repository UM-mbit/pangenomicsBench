# PangenomicsBench
This is a benchmark suite of pangenomics kernels from popular tools.
It includes the following kernels:
| Kernel Name | Toolchain     | Type of Kernel          | Summary                                                                                      |
|-------------|---------------|-------------------------|----------------------------------------------------------------------------------------------|
| GSSW        | Vg Map        | 2D dynamic programming. Alignment | Farrar's style SIMD parallelization with POA-style lookups to handle the graph                |
| GBV         | GraphAlginer  | 2D dynamic programming. Alignment | Myers bitvector extended to graph. Uses a priority queue to order computations, allowing alignment to cyclic graphs |
| GBWT        | Vg Giraffe    | Table lookups. Indexing | GBWT index find query. Used to extend clustered seed hits in Giraffe.                        |
| GWFA        | Minigraph     | 2D dynamic programming. Alignment | Used in Minigraph for alignment and graph building. Although GWFA is used in the chaining step to link seed anchors, computationally, it resembles a dynamic |
| TC          | Seqwish       | Union-find, sorting. Pangenome Graph Building | Used in Seqwish to construct pangenome graph nodes from all-to-all alignments |
| PGSGD       | Odgi layout   | Path-Guided Stochastic Gradient Descent. Layout generation | Utilizes PGSGD to compute 2D layouts of pangenome graphs from either PGGB or minigraph-cactus flow |
| PGSGD-GPU   | Odgi layout   | Path-Guided Stochastic Gradient Descent. Layout generation | Utilizes PGSGD to compute 2D layouts of pangenome graphs from either PGGB or minigraph-cactus flow. GPU accelerated |

## Setup
1. Please ensure all [dependencies](#dependencies) are met.
   For GSSW, which depends on vg, please `cd Gssw/deps/vg` and then follow the
   instructions in the [vg README](Gssw/deps/vg/README.md) to install those
   dependencies. (`make get-deps` will work for Ubuntu)
2. Clone the repository and all submodules with 
   `git clone --recursive git@github.com:UM-mbit/pangenomicsBench.git`
3. Install the profiling tools. Needed for profiling analysis. 
   `cd ProfileScripts && bash build.sh && cd ..`
4. Download the datasets. 
   `wget https://genomicsbench.eecs.umich.edu/Kernels.tar.gz && tar -xvzf Kernels.tar.gz`
5. Set local environment variables:
   + `VTUNE_HOME` - Path to the VTune installation directory. e.g.
     `/opt/intel/oneapi/vtune/latest`
   + `KERNEL_DATA` - Path to the dataset directory (called Kernels)
6. Ensure cmake can locate your CUDA installation (for PGSGD-GPU). Potentially,
   you might need to set the environment variable `CUDA_HOME` and update your `PATH`
   and `LD_LIBRARY_PATH` similar to this:
   ```
   export CUDA_HOME=/usr/local/cuda
   export PATH=$CUDA_HOME/bin:$PATH
   export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
   ```
6. Build the kernels by running the build script. It will print build status of
   kernels at the end of the script. If a kernel fails
   enter individual kernel directories, read the README, and attempt manual
   build. Note, the compiler used in our paper is specified in the Makefile.
   Others may be used, but are untested. build.sh is tested with zsh and bash. 
   Conda must be initialized for the shell you run it with.
   `source build.sh`
7. Run the CPU kernels with the run script.
   `python mainRun.py`
   By default the script will run the kernels once with timing collection.
   To run with other profiling options read the header comment of `mainRun.py`
   This will produce `AllRunsOut` which includes all of the output data. The
   directory structure is shown below:
   ```
       AllRunsOut
    ├── <KernelName>
    │   ├── KernelOuts //contains outputs of the kernel
    │   ├── Logs //contains logs of each analysis run e.g. vanillaApp.log
    │   │   ├── vanillaApp.log
    │   │   └── ...
    │   ├── Profiles //contains vtune profiles if they were collected
    │   │   ├── ...
    │   ├── Reports //contains reports from the vtune profiles
    │   │   ├── ...
    │   └── Results //contains summarized results from the analyses runs
    │       ├── vanillaRunTimes.txt
    │       └── ...
    └── <KernelName2>
        ...
    ```

    You can check that all the files were correctly generated by running 
    `bash checkAllRuns.sh`, which lists the files in the Results dir for each
    kernel. This is also run at the end of mainRun.py

   Kernels can also be run individually. Usually as:
   `./bin/kernel.prof <path to input> [optional: numIterations]`
   numIterations can be used to stop after `n` inputs to control the duration
   without modifying the dataset.
   See the README for each kernel for more information.
8. Running GPU kernels:  
   Timing analysis can be run with `runGpu.sh`. Tsunami results will be written 
   to `tsunamiTiming.txt` and PGSGD results will be written to TODO

   More detailed instructions for running the gpu kernels, as well as
   information for running the NCU profiling can be found in the GPU kernel
   directories.
## Dependencies
All experiments are run on a linux system (Tested for Ubuntu 24.04, and 22.04).
### To build CPU kernels
- conda (tested with 24.7.1). Must be initialized for the shell you are running.
  e.g. run `conda init bash`
- cmake (tested with 3.26.0)
- gcc/g++ (We use gcc 9, 11, and 13). Any one of these should compile, but we
  used the following for the results in the paper:
    - GSSW uses gcc 11  
    - GBV use gcc 13  
    - GBWT uses gcc 9  
    - GWFA uses gcc 11  
    - GpuWfa uses gcc 13  
    - TC uses gcc 11
    - PGSGD uses gcc 11
    - PGSGD uses gcc 11 and CUDA 12.4
- Dependencies for specific tool dependencies are enumerated in the readmes for
  their submodules.
### For CPU profiling
- Intel VTune Profiler (tested with 2025.1.0)
### For GPU code
- Cuda (tested with 12.4)
- NCU (tested with 2024.1.0)
